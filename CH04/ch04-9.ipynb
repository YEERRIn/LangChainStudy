{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "llm = ChatOllama(model=\"gemma:7b\")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"{topic} 에 대하여 간략히 설명해 줘.\")\n",
    "\n",
    "\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "print(chain.invoke({\"topic\": \"deep learning\"}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic = {\"topic\": \"Covid 19\"} \n",
    "\n",
    "\n",
    "for chunks in chain.stream(topic):\n",
    "    print(chunks, end=\"\", flush=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic = {\"topic\": \"LangChain\"}  \n",
    "\n",
    "async for chunks in chain.astream(\n",
    "    topic\n",
    "):  \n",
    "    print(chunks, end=\"\", flush=True)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_models import ChatOllama\n",
    "\n",
    "llm = ChatOllama(\n",
    "    model=\"gemma:7b\", \n",
    "    format=\"json\", \n",
    "    temperature=0,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "messages = [\n",
    "    HumanMessage(\n",
    "     \n",
    "        content=\"Tell me 10 places to travel in Europe. resonse in JSON format.\"\n",
    "    )\n",
    "]\n",
    "\n",
    "chat_model_response = llm.invoke(messages) \n",
    "print(chat_model_response.content) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "json_schema = {\n",
    "    \"title\": \"Person\",\n",
    "    \"description\": \"Identifying information about a person.\",\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "        \"name\": {\"title\": \"Name\", \"description\": \"The person's name\", \"type\": \"string\"},\n",
    "        \"age\": {\"title\": \"Age\", \"description\": \"The person's age\", \"type\": \"integer\"},\n",
    "        \"occupation\": {\n",
    "            \"title\": \"Occupation\",\n",
    "            \"description\": \"The person's Occupation\",\n",
    "            \"type\": \"string\",\n",
    "        },\n",
    "    },\n",
    "    \"required\": [\"name\", \"age\"],\n",
    "}\n",
    "\n",
    "llm = ChatOllama(model=\"gemma:7b\") \n",
    "\n",
    "messages = [\n",
    "    HumanMessage(\n",
    "    \n",
    "        content=\"Please tell me about a person using the following JSON schema:\"\n",
    "    ),\n",
    "    HumanMessage(content=\"{dumps}\"),\n",
    "    HumanMessage(\n",
    "       \n",
    "        content=\"\"\"Now, considering the schema, please describe following person:\n",
    "        Her name is Eun-Chae Lee, she is 25 years old, and she is a software engineer.\n",
    "        \"\"\"\n",
    "    ),\n",
    "]\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    messages\n",
    ")  \n",
    "\n",
    "dumps = json.dumps(json_schema, indent=2)\n",
    "\n",
    "chain = (\n",
    "    prompt | llm | StrOutputParser()\n",
    ")  \n",
    "\n",
    "print(chain.invoke({\"dumps\": dumps}))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade --quiet  pillow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "from io import BytesIO\n",
    "\n",
    "from IPython.display import HTML, display\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def convert_to_base64(pil_image):\n",
    "    \"\"\"\n",
    "    PIL 이미지를 Base64로 인코딩된 문자열로 변환합니다.\n",
    "\n",
    "    :param pil_image: PIL 이미지\n",
    "    :return: 크기 조정된 Base64 문자열\n",
    "    \"\"\"\n",
    "\n",
    "    buffered = BytesIO()\n",
    "    pil_image.save(buffered, format=\"JPEG\") \n",
    "    img_str = base64.b64encode(buffered.getvalue()).decode(\"utf-8\")\n",
    "    return img_str\n",
    "\n",
    "\n",
    "def plt_img_base64(img_base64):\n",
    "    \"\"\"\n",
    "    Base64로 인코딩된 문자열을 이미지로 표시합니다.\n",
    "\n",
    "    :param img_base64:  Base64 문자열\n",
    "    \"\"\"\n",
    "   \n",
    "    image_html = f'<img src=\"data:image/jpeg;base64,{img_base64}\" />'\n",
    "\n",
    "    display(HTML(image_html))\n",
    "\n",
    "\n",
    "file_path = \"./images/jeju-beach.jpg\"\n",
    "pil_image = Image.open(file_path)\n",
    "\n",
    "image_b64 = convert_to_base64(pil_image)\n",
    "plt_img_base64(image_b64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "llm = ChatOllama(model=\"llava:7b\", temperature=0)\n",
    "\n",
    "\n",
    "def prompt_func(data): \n",
    "    text = data[\"text\"] \n",
    "    image = data[\"image\"]  \n",
    "\n",
    "    image_part = { \n",
    "        \"type\": \"image_url\", \n",
    "        \"image_url\": f\"data:image/jpeg;base64,{image}\", \n",
    "    }\n",
    "\n",
    "    content_parts = [] \n",
    "\n",
    "    text_part = {\"type\": \"text\", \"text\": text} \n",
    "\n",
    "    content_parts.append(image_part)\n",
    "    content_parts.append(text_part)  \n",
    "\n",
    "    return [HumanMessage(content=content_parts)] \n",
    "\n",
    "chain = prompt_func | llm | StrOutputParser()\n",
    "\n",
    "query_chain = chain.invoke( \n",
    "    {\"text\": \"Describe a picture in bullet points.\", \"image\": image_b64}\n",
    ")\n",
    "\n",
    "print(query_chain) \n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
