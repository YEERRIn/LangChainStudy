{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "# API KEY 정보로드\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith 추적을 시작합니다.\n",
      "[프로젝트명]\n",
      "CH01-Basic\n"
     ]
    }
   ],
   "source": [
    "from langchain_teddynote import logging\n",
    "\n",
    "# 프로젝트 이름을 입력합니다.\n",
    "logging.langsmith(\"CH01-Basic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_teddynote.messages import stream_response  # 스트리밍 출력\n",
    "from langchain_core.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['country'], template='{country}의 수도는 어디인가요?')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# template 정의\n",
    "template = \"{country}의 수도는 어디인가요?\"\n",
    "\n",
    "# from_template 메소드를 이용하여 PromptTemplate 객체 생성\n",
    "prompt_template = PromptTemplate.from_template(template)\n",
    "prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'대한민국의 수도는 어디인가요?'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#prompt 생성\n",
    "prompt = prompt_template.format(country=\"대한민국\")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'미국의 수도는 어디인가요?'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prompt 생성\n",
    "prompt = prompt_template.format(country=\"미국\")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    max_tokens=2048,\n",
    "    temperature=0.1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prompt를 Prompt Template 객체로 생성합니다 \n",
    "\n",
    "prompt = PromptTemplate.from_template(\"{topic} 에 대해 쉽게 설명해주세요.\")\n",
    "\n",
    "model = ChatOpenAI()\n",
    "\n",
    "chain = prompt | model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='인공지능 모델의 학습 원리는 데이터를 입력으로 받아서 패턴이나 규칙을 학습하는 과정입니다. 모델은 입력된 데이터를 분석하여 특정한 작업을 수행하는 방법을 학습하고, 이를 기반으로 새로운 데이터에 대한 예측이나 결정을 내립니다.\\n\\n학습 과정은 크게 입력층, 은닉층, 출력층으로 구성된 인공신경망을 사용합니다. 입력층에서 데이터를 받아 은닉층을 통해 다양한 가중치와 편향을 조절하면서 출력층으로 결과를 도출합니다. 이 때, 모델은 학습 데이터에 대한 오차를 최소화하기 위해 가중치와 편향을 조정하며 학습을 진행합니다.\\n\\n모델은 일정 수준의 정확도를 달성할 때까지 반복적으로 학습을 진행하며, 학습 데이터에 대한 예측이 얼마나 정확한지를 측정하여 성능을 평가합니다. 이렇게 학습된 모델은 새로운 데이터를 입력으로 받아 예측이나 분류를 수행할 수 있습니다.', response_metadata={'token_usage': {'completion_tokens': 371, 'prompt_tokens': 33, 'total_tokens': 404}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-f6553f0f-3324-4e0e-84cb-a3f547aee800-0', usage_metadata={'input_tokens': 33, 'output_tokens': 371, 'total_tokens': 404})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#input 딕셔너리에 주제를 인공지능 모델의 학습 원리로 설정 \n",
    "\n",
    "input = {\"topic\": \"인공지능 모델의 학습 원리\"}\n",
    "\n",
    "# prompt 객체와 model 객체를 파이프(|) 연산자로 연결하고 invoke 메서드를 사용하여 input을 전달합니다.\n",
    "# 이를 통해 AI 모델이 생성한 메시지를 반환합니다.\n",
    "chain.invoke(input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인공지능 모델의 학습 원리는 데이터를 입력으로 받아들이고, 이를 분석하여 패턴이나 규칙을 찾아내는 과정입니다. 모델은 초기에는 데이터를 이해하지 못하고 무작위로 판단을 내리지만, 학습 과정을 거치면서 점차 데이터의 패턴을 파악하고 예측을 수행할 수 있게 됩니다.\n",
      "\n",
      "이를 위해 모델은 학습 데이터를 이용해 가중치와 편향을 조정하며 최적의 결정 경계를 찾아내는 과정을 거칩니다. 즉, 모델은 학습 데이터를 통해 오차를 최소화하도록 스스로 학습하고, 새로운 데이터에 대해 정확한 예측을 할 수 있도록 개선되어 갑니다.\n",
      "\n",
      "이러한 인공지능 모델의 학습 원리는 지도학습, 비지도학습, 강화학습 등 다양한 방법으로 이루어질 수 있으며, 모델의 구조나 사용되는 알고리즘에 따라 학습 과정과 결과가 달라질 수 있습니다."
     ]
    }
   ],
   "source": [
    "#스트리밍 출력을 위한 요청 \n",
    "answer = chain.stream(input)\n",
    "stream_response(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 프롬프트, 모델, 출력 파서를 여녁ㄹ하여 처리 체인을 구성 \n",
    "\n",
    "chain = prompt | model | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'인공지능 모델의 학습 원리는 데이터를 통해 패턴을 학습하는 과정입니다. 먼저, 모델에 입력되는 데이터를 기반으로 모델은 주어진 작업을 수행하고, 그 결과를 예측합니다. 이때, 모델은 예측 결과와 실제 결과 간의 차이를 최소화하기 위해 내부 매개변수를 조정하며, 이를 통해 모델은 데이터 간의 패턴을 학습하게 됩니다. 이러한 과정을 반복하면서 모델은 점차적으로 더 정확한 예측을 할 수 있게 되는 것이죠. 따라서, 인공지능 모델의 성능은 주어진 데이터의 양과 질, 그리고 모델의 구조와 학습 알고리즘에 따라 달라지게 됩니다.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = {\"topic\": \"인공지능 모델의 학습 원리\"}\n",
    "chain.invoke(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#스트리밍 출력을 위한 요청 \n",
    "answer = chain.stream(input)\n",
    "\n",
    "#스트리밍 출력 \n",
    "stream_response(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "\n",
    "당신은 영어를 가르치는 10년차 영어 선생님입니다. 상황에 [FORMAT]에 영어 회화를 작성해주세요. \n",
    "\n",
    "상황: \n",
    "{question}\n",
    "\n",
    "FROMAT:\n",
    "- 영어 회화:\n",
    "- 한글 해석: \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "#프롬프트 템플릿을 이용하여 프롬프트를 생성 \n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "#chatOpenAI 챗 모델을 초기화 \n",
    "model = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "\n",
    "#문자열 출력 파서 초기화\n",
    "output_partser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#체인 구성\n",
    "\n",
    "chain = prompt | model | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 영어 회화: I'd like to order some food at the restaurant.\n",
      "- 한글 해석: 저는 식당에 가서 음식을 주문하고 싶어요."
     ]
    }
   ],
   "source": [
    "# 완성된 Chain을 실행하여 답변을 얻습니다.\n",
    "# 스트리밍 출력을 위한 요청\n",
    "answer = chain.stream({\"question\": \"저는 식당에 가서 음식을 주문하고 싶어요\"})\n",
    "# 스트리밍 출력\n",
    "stream_response(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "\n",
    "당신은 백화점 직원입니다. 주어진 [FORMAT]에 맞추어 고객에게 상품을 설명해보세요. \n",
    "\n",
    "상품: \n",
    "{question}\n",
    "\n",
    "FROMAT:\n",
    "- 상품의 이름 언급\n",
    "- 상품의 장점 2줄 이내로 설명 \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "#프롬프트 템플릿을 이용하여 프롬프트를 생성 \n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "#chatOpenAI 챗 모델을 초기화 \n",
    "model = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "\n",
    "#문자열 출력 파서 초기화\n",
    "output_partser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#체인 구성\n",
    "\n",
    "chain = prompt | model | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "상품: 운동화\n",
      "\n",
      "이 운동화는 경량으로 제작되어 편안한 착용감을 제공합니다. 또한 트렌디한 디자인으로 다양한 스타일에 매치하기 좋습니다."
     ]
    }
   ],
   "source": [
    "# 완성된 Chain을 실행하여 답변을 얻습니다.\n",
    "# 스트리밍 출력을 위한 요청\n",
    "answer = chain.stream({\"question\": \"운동화\"})\n",
    "# 스트리밍 출력\n",
    "stream_response(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith 추적을 하지 않습니다.\n"
     ]
    }
   ],
   "source": [
    "logging.langsmith(\"CH01-Basic\", set_enable=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a092fd226f6fc88450915dcb73abf6d49f4bd6515daca38907c3a18dfe5f9dd0"
  },
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
